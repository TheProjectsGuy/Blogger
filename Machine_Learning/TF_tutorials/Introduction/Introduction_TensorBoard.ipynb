{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In this notebook, we'll discuss how tensorboard, an important tool in tensorflow, works. If you haven't checked out the [introduction to tensorflow notebook](Introduction.ipynb) yet, I highly recommend that you check that out first.\n",
    "\n",
    "Let's get started with tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard\n",
    "TensorBoard is an interactive tool to visualize the **DAG** (Directed Acyclic Graph) that tensorflow makes in the session and passes tensors through. It's a helpful tool in visualizing training sessions or even basically know what your code does. \n",
    "\n",
    "In order to use this, you need a summary writer. TensorBoard is launched in your browser (it's run on a port). TensorFlow keeps a directory maintained for the session results. This directory is very useful while training big models because it let's you resume training from a previous checkpoint.\n",
    "\n",
    "- [tf.summary.merge_all](https://www.tensorflow.org/api_docs/python/tf/summary/merge_all) : Merge all the summary writers so that everything comes in the default graph\n",
    "- [tf.summary.FileWriter](https://www.tensorflow.org/api_docs/python/tf/summary/FileWriter) : Initialize a file writer in the given directory and write the given graph into it\n",
    "\n",
    "**Note** : Run the below cell only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.24881\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(17, dtype=tf.float32, name=\"const_X\")\n",
    "y = tf.constant(20, dtype=tf.float32, name=\"const_Y\")\n",
    "\n",
    "z = tf.Variable(tf.sqrt(x**2 + y**2), name=\"Z\")\n",
    "model_tb = tf.initializers.variables([z])\n",
    "with tf.Session() as sess:\n",
    "    tf.summary.merge_all()\n",
    "    tf.summary.FileWriter(\"./summaries/logs\", sess.graph)\n",
    "    sess.run(model_tb)\n",
    "    print(sess.run(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running this cell, open a terminal and type the following\n",
    "```bash\n",
    "tensorboard --logdir=./summaries/logs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source the activation file for the python environment first (if you've used virtualenv). You must see an output something like this.\n",
    "![Terminal Output](TensorBoard_terminal_output.png \"Terminal output\")\n",
    "Open a web browser and go to the address shown in the command, here it's Jarvis:6006 (Use http:// in the beginning if that doesn't work). Once the TensorBoard starts up, it shows you the entire DAG file in a very interactive manner.\n",
    "![TensorBoard Output](TensorBoard_output_graph.png \"TensorBoard output\")\n",
    "You can see that it shows you all mathematical operations in detail. The one on the left is the main graph, the small two node graph on the right is just the initializer for the variable (it was constructed for the global variables initializer). Let's discuss parts of this graph\n",
    "\n",
    "*Nodes* : All the boxes, each box performs a function\n",
    "*Tensors* : These flow in the data lines (edges) which are arrows leading them from one node to another.\n",
    "**Auxiliary Nodes** : These are nodes that are responsible for getting the values out of tensors.\n",
    "**Main Graph** : The main graph for getting the values. This shows the execution flow. Let's explore parts of it bottom to top.\n",
    "- Bottom most nodes are *const_X*, *const_Y* and *y* (a node that tensorflow created and gave the value 2). You can click on them and know their values. This is where the variables have spawned.\n",
    "- Then, we get the *pow* nodes (one on both sides), this is for the squaring operation.\n",
    "- Then, we have an *add* node, this is to add the results of the two branches.\n",
    "- Then, we have *Sqrt* node, which performs the square root\n",
    "- Then the result is stored in a variable *Z*.\n",
    "    - It's encapsulated (nodes responsible for variable handling are grouped into one). You can double click on it and get more detals. \n",
    "    - Basically, it consists *Assign* node to assign a value, it references node *(Z)* to say that it's assigning the input to *(Z)*. And then we read the value, so it contains the *read* node.\n",
    "\n",
    "You can of course explore various options on the left side of the window, we'll explore some more later.\n",
    "You can now try running the calculation again, you'll observe that tensorflow doesn't discard the previous execution, it simply merges the new graph. It just overlays the nodes of the newer execution.\n",
    "\n",
    "## Conclusion\n",
    "We have now completed the basics of TensorFlow and tensorboard."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
